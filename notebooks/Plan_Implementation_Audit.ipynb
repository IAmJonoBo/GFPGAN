{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20028f05",
   "metadata": {},
   "source": [
    "# Plan Implementation Audit\n",
    "\n",
    "This notebook validates the phased plan and records results in a persistent TODO ledger that never overwrites prior entries.\n",
    "\n",
    "Outline:\n",
    "- Section 1: Repo/env helpers and quick environment printouts\n",
    "- Section 2: Persistent TODO ledger (append/merge, idempotent)\n",
    "- Section 3+: Verification cells for gated features, flags, and detector heuristics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d82b424",
   "metadata": {},
   "source": [
    "# Plan Implementation Audit\n",
    "This notebook validates the phased plan implementation and maintains a persistent TODO ledger without overwriting prior entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60680e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /Users/jonathanbotha/GitHub/GFPGAN\n",
      "Python: 3.12.2\n",
      "Torch: not available: No module named 'torch'\n",
      "uv: uv 0.6.17 (8414e9f3d 2025-04-25)\n"
     ]
    }
   ],
   "source": [
    "# Section 1: Locate repository root, environment, and helpers\n",
    "import os, sys, json, subprocess, shutil, time, pathlib, platform\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "# In notebooks, __file__ is unavailable; walk up from CWD until we find pyproject.toml\n",
    "repo_root = pathlib.Path.cwd().resolve()\n",
    "while repo_root != repo_root.parent and not (repo_root / 'pyproject.toml').exists():\n",
    "    repo_root = repo_root.parent\n",
    "assert (repo_root / 'pyproject.toml').exists(), 'pyproject.toml not found'\n",
    "\n",
    "# Validate expected src layout if present; do not hard-fail if restoria is absent\n",
    "assert (repo_root / 'src' / 'gfpp').exists(), 'src/gfpp missing'\n",
    "\n",
    "\n",
    "def run(cmd: List[str], cwd: Optional[str]=None, env: Optional[Dict[str,str]]=None) -> Tuple[int,str,str]:\n",
    "    p = subprocess.Popen(cmd, cwd=cwd or str(repo_root), env={**os.environ, **(env or {})}, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    out, err = p.communicate()\n",
    "    return p.returncode, out, err\n",
    "\n",
    "\n",
    "def read_text(path: str) -> str:\n",
    "    return pathlib.Path(path).read_text()\n",
    "\n",
    "\n",
    "def write_text(path: str, data: str) -> None:\n",
    "    p = pathlib.Path(path)\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    p.write_text(data)\n",
    "\n",
    "\n",
    "def read_toml(path: str) -> Dict[str, Any]:\n",
    "    import tomllib as toml\n",
    "    return toml.loads(read_text(path))\n",
    "\n",
    "\n",
    "def write_toml(path: str, obj: Dict[str, Any]) -> None:\n",
    "    try:\n",
    "        import tomli_w\n",
    "    except Exception:\n",
    "        raise RuntimeError('tomli_w is required to write TOML in this notebook context')\n",
    "    write_text(path, tomli_w.dumps(obj))\n",
    "\n",
    "\n",
    "def read_yaml(path: str) -> Any:\n",
    "    from ruamel.yaml import YAML\n",
    "    y = YAML()\n",
    "    return y.load(read_text(path))\n",
    "\n",
    "\n",
    "def write_yaml(path: str, obj: Any) -> None:\n",
    "    from ruamel.yaml import YAML\n",
    "    y = YAML()\n",
    "    s_path = pathlib.Path(path)\n",
    "    s_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with s_path.open('w') as f:\n",
    "        YAML().dump(obj, f)\n",
    "\n",
    "\n",
    "def safe_patch_file(path: str, patch_fn):\n",
    "    p = pathlib.Path(path)\n",
    "    orig = p.read_text() if p.exists() else ''\n",
    "    new = patch_fn(orig)\n",
    "    if new != orig:\n",
    "        tmp = p.with_suffix(p.suffix + '.tmp')\n",
    "        tmp.write_text(new)\n",
    "        tmp.replace(p)\n",
    "    return p\n",
    "\n",
    "print('Repo root:', repo_root)\n",
    "print('Python:', platform.python_version())\n",
    "try:\n",
    "    import torch\n",
    "    print('Torch:', torch.__version__, 'CUDA', getattr(torch, 'cuda', None) and torch.cuda.is_available())\n",
    "except Exception as e:\n",
    "    print('Torch: not available:', e)\n",
    "rc, out, err = run(['uv', '--version'])\n",
    "print('uv:', out.strip() if rc==0 else f'not available (rc={rc})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e1f1d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 9999,\n",
       " 'title': 'merge-test',\n",
       " 'status': 'PASS',\n",
       " 'notes': ['first', 'second', 'merge works'],\n",
       " 'updated_at': 1758199188.039704}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section 2: Persistent TODO ledger (idempotent, append/merge; no overwrites)\n",
    "import json, time, pathlib\n",
    "LEDGER = repo_root / '.tools' / 'todo_ledger.json'\n",
    "LEDGER.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_ledger():\n",
    "    if LEDGER.exists():\n",
    "        try:\n",
    "            return json.loads(LEDGER.read_text())\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "def save_ledger(items):\n",
    "    tmp = LEDGER.with_suffix('.json.tmp')\n",
    "    tmp.write_text(json.dumps(items, indent=2))\n",
    "    tmp.replace(LEDGER)\n",
    "\n",
    "def upsert_todo(tid: int, title: str | None = None, status: str | None = None, note: str | None = None):\n",
    "    items = load_ledger()\n",
    "    found = None\n",
    "    for it in items:\n",
    "        if it.get('id') == tid:\n",
    "            found = it\n",
    "            break\n",
    "    if not found:\n",
    "        found = {'id': tid, 'title': title or '', 'status': status or 'PENDING', 'notes': [], 'updated_at': time.time()}\n",
    "        items.append(found)\n",
    "    if title: found['title'] = title\n",
    "    if status: found['status'] = status\n",
    "    if note:\n",
    "        found.setdefault('notes', [])\n",
    "        found['notes'].append(note)\n",
    "    found['updated_at'] = time.time()\n",
    "    save_ledger(items)\n",
    "    return found\n",
    "\n",
    "def record_check(tid: int, status: str, note: str):\n",
    "    return upsert_todo(tid, status=status, note=note)\n",
    "\n",
    "# Unit test for merge behavior (simple assert)\n",
    "items_before = load_ledger()\n",
    "_a = upsert_todo(9999, title='merge-test', status='PENDING', note='first')\n",
    "_b = upsert_todo(9999, note='second')\n",
    "items_after = load_ledger()\n",
    "assert any(it.get('id')==9999 for it in items_after)\n",
    "assert any('first' in it.get('notes', []) for it in items_after if it.get('id')==9999)\n",
    "assert any('second' in it.get('notes', []) for it in items_after if it.get('id')==9999)\n",
    "record_check(9999, 'PASS', 'merge works')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f7760",
   "metadata": {},
   "source": [
    "# Section 3: Plan verification checks\n",
    "\n",
    "This section runs lightweight checks (no model downloads) and records PASS/FAIL into the persistent ledger.\n",
    "\n",
    "We avoid heavy deps by:\n",
    "- Using dry-run or internal helpers where possible\n",
    "- Monkeypatching probes instead of running detectors\n",
    "- Performing static-source checks when runtime validation needs unavailable dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ff00b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeFormer licensing gate: PRESENT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 1001,\n",
       " 'title': '',\n",
       " 'status': 'PASS',\n",
       " 'notes': ['CodeFormer gate strings present in gfpp/cli.py'],\n",
       " 'updated_at': 1758199359.154336}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check A: CodeFormer licensing gate is enforced in CLI (static check)\n",
    "from pathlib import Path\n",
    "cli_src = (repo_root / 'src' / 'gfpp' / 'cli.py').read_text()\n",
    "assert 'Allow non-commercial backends' in cli_src\n",
    "assert 'RESTORIA_ALLOW_NONCOMMERCIAL' in cli_src\n",
    "assert '--allow-noncommercial' in cli_src\n",
    "print('CodeFormer licensing gate: PRESENT')\n",
    "record_check(1001, 'PASS', 'CodeFormer gate strings present in gfpp/cli.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd49b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision/tiling flags: PRESENT and plumbed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 1002,\n",
       " 'title': '',\n",
       " 'status': 'PASS',\n",
       " 'notes': ['Precision/tiling flags wired in CLI and GFPGAN restorer'],\n",
       " 'updated_at': 1758199366.222558}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check B: Precision/tiling flags are accepted and plumbed to cfg (static check)\n",
    "cli_src = (repo_root / 'src' / 'gfpp' / 'cli.py').read_text()\n",
    "assert '--precision' in cli_src and 'choices=[\"auto\", \"fp16\", \"bf16\", \"fp32\"]' in cli_src\n",
    "assert '--tile' in cli_src and '--tile-overlap' in cli_src\n",
    "# Verify restorer reads precision and tile (gfpgan adapter)\n",
    "rest_src = (repo_root / 'src' / 'gfpp' / 'restorers' / 'gfpgan.py').read_text()\n",
    "assert 'precision = str(cfg.get(\"precision\", \"auto\"))' in rest_src\n",
    "assert 'tile = int(cfg.get(\"tile\", 0))' in rest_src and 'tile_overlap' in rest_src\n",
    "print('Precision/tiling flags: PRESENT and plumbed')\n",
    "record_check(1002, 'PASS', 'Precision/tiling flags wired in CLI and GFPGAN restorer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345aa050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector heuristic and insightface->scrfd mapping: PRESENT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 1003,\n",
       " 'title': '',\n",
       " 'status': 'PASS',\n",
       " 'notes': ['Detector heuristic and mapping implemented'],\n",
       " 'updated_at': 1758199377.991779}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check C: Detector heuristic & mapping (planner + GFPGAN restorer)\n",
    "orch_src = (repo_root / 'src' / 'gfpp' / 'core' / 'orchestrator.py').read_text()\n",
    "assert 'detector_choice' in orch_src and 'params[\"detector\"]' in orch_src\n",
    "rest_src = (repo_root / 'src' / 'gfpp' / 'restorers' / 'gfpgan.py').read_text()\n",
    "assert \"requested_det == \\\"insightface\\\"\" in rest_src and \"requested_det = \\\"scrfd\\\"\" in rest_src\n",
    "print('Detector heuristic and insightface->scrfd mapping: PRESENT')\n",
    "record_check(1003, 'PASS', 'Detector heuristic and mapping implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54978bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face probe ordering (SCRFD first): PRESENT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 1004,\n",
       " 'title': '',\n",
       " 'status': 'PASS',\n",
       " 'notes': ['Face probe SCRFD preference implemented'],\n",
       " 'updated_at': 1758199796.451862}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check C: Face probe prefers SCRFD when available (static source presence)\n",
    "probe_src = (repo_root / 'src' / 'gfpp' / 'probe' / 'faces.py').read_text()\n",
    "assert '_detect_with_insightface' in probe_src and '_detect_with_facexlib' in probe_src\n",
    "assert 'res = _detect_with_insightface(path)' in probe_src\n",
    "print('Face probe ordering (SCRFD first): PRESENT')\n",
    "record_check(1004, 'PASS', 'Face probe SCRFD preference implemented')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gfpgan (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
