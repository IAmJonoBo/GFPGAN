{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GFPGAN Colab Demo (Fork)\n",
    "\n",
    "This Colab notebook installs dependencies, clones this fork, downloads pretrained weights automatically, and runs the GFPGAN inference script on sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d9709",
   "metadata": {
    "id": "env-setup"
   },
   "outputs": [],
   "source": [
    "#@title Install dependencies\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def run(cmd, shell=False, check=True):\n",
    "    print(\">>\", cmd if shell else \" \".join(cmd))\n",
    "    if shell:\n",
    "        return subprocess.run(cmd, shell=True, check=check)\n",
    "    else:\n",
    "        return subprocess.run(cmd, check=check)\n",
    "\n",
    "print(sys.version)\n",
    "\n",
    "# CI smoke: skip heavy installs when NB_CI_SMOKE is set\n",
    "if os.environ.get(\"NB_CI_SMOKE\"):\n",
    "    print(\"NB_CI_SMOKE=1: printing Python version and exiting install cell\")\n",
    "    raise SystemExit(0)\n",
    "\n",
    "# Upgrade pip tooling quietly\n",
    "run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"--quiet\", \"pip\", \"setuptools\", \"wheel\"])\n",
    "# Ensure IPython deps are satisfied to avoid resolver warnings\n",
    "run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"-U\", \"ipython\", \"jedi\"])\n",
    "\n",
    "# Install torch (GPU wheels if NVIDIA present)\n",
    "has_nvidia = shutil.which(\"nvidia-smi\") is not None\n",
    "if has_nvidia:\n",
    "    print(\"Detected NVIDIA GPU; installing CUDA wheels\")\n",
    "    run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"torch\", \"torchvision\", \"torchaudio\", \"--index-url\", \"https://download.pytorch.org/whl/cu121\"])\n",
    "else:\n",
    "    print(\"No NVIDIA GPU; installing CPU wheels\")\n",
    "    run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"torch\", \"torchvision\", \"torchaudio\"])\n",
    "\n",
    "# Core deps: match repo constraints (basicsr <= 1.4.2)\n",
    "run([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"--no-cache-dir\", \"--upgrade\",\n",
    "     \"basicsr<=1.4.2\", \"facexlib\", \"realesrgan\", \"opencv-python\", \"tqdm\", \"numpy\", \"PyYAML\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a56a79c",
   "metadata": {
    "id": "clone-repo"
   },
   "outputs": [],
   "source": [
    "#@title Clone this fork\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "REPO_URL = \"https://github.com/IAmJonoBo/GFPGAN.git\"\n",
    "REPO_DIR = \"GFPGAN\"\n",
    "\n",
    "if not os.path.isdir(REPO_DIR):\n",
    "    print(\"Cloning repo...\")\n",
    "    subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, REPO_DIR], check=False)\n",
    "else:\n",
    "    print(\"Repo exists, skipping clone.\")\n",
    "\n",
    "print(\"Repo at:\", os.path.abspath(REPO_DIR))\n",
    "try:\n",
    "    print(\"Listing inputs dir:\")\n",
    "    subprocess.run([\"ls\", \"-la\", \"inputs\"], cwd=REPO_DIR, check=False)\n",
    "except Exception as e:\n",
    "    print(\"Note: inputs directory may not exist yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bced545",
   "metadata": {
    "id": "run-inference"
   },
   "outputs": [],
   "source": [
    "#@title Run inference on sample images\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "repo_dir = \"GFPGAN\"\n",
    "cmd = [sys.executable, \"inference_gfpgan.py\", \"-i\", \"inputs/whole_imgs\", \"-o\", \"results\", \"-v\", \"1.4\", \"-s\", \"2\"]\n",
    "print(\"Running:\", \" \".join(cmd))\n",
    "res = subprocess.run(cmd, cwd=repo_dir, check=False)\n",
    "print(\"Exit code:\", res.returncode)\n",
    "print(\"Results written to ./GFPGAN/results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b7758",
   "metadata": {
    "id": "display-results"
   },
   "outputs": [],
   "source": [
    "# @title Display a few restored images\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "\n",
    "base = \"GFPGAN/results/restored_imgs\"\n",
    "imgs = sorted(glob.glob(os.path.join(base, \"*\")))[:4]\n",
    "print(f\"Displaying {len(imgs)} images from\", base)\n",
    "for p in imgs:\n",
    "    try:\n",
    "        display(Image(filename=p))\n",
    "    except Exception:\n",
    "        print(\"Could not display:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b78da",
   "metadata": {
    "id": "upload-run"
   },
   "outputs": [],
   "source": [
    "# @title Upload your own images and run GFPGAN\n",
    "# @markdown Upload one or more images; they will be processed with the settings below.\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Guard: if not in Colab, skip gracefully\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "upload_dir = \"GFPGAN/uploads\"\n",
    "os.makedirs(upload_dir, exist_ok=True)\n",
    "\n",
    "if IN_COLAB:\n",
    "    uploaded = files.upload()\n",
    "    for name, data in uploaded.items():\n",
    "        with open(name, \"wb\") as f:\n",
    "            f.write(data)\n",
    "        shutil.move(name, os.path.join(upload_dir, os.path.basename(name)))\n",
    "else:\n",
    "    print(\"Not running in Colab; skipping upload UI.\")\n",
    "\n",
    "# Inference parameters\n",
    "version = \"1.4\"  # @param ['1', '1.2', '1.3', '1.4']\n",
    "scale = 2  # @param {type: 'integer'}\n",
    "only_center_face = False  # @param {type: 'boolean'}\n",
    "aligned = False  # @param {type: 'boolean'}\n",
    "autopilot = False  # @param {type: 'boolean'}\n",
    "hardware_aware = True  # @param {type: 'boolean'}\n",
    "select_by = \"sharpness\"  # @param ['sharpness', 'identity']\n",
    "\n",
    "print(\"Running inference on uploads...\")\n",
    "cmd = [sys.executable, \"inference_gfpgan.py\", \"-i\", \"uploads\", \"-o\", \"results\", \"-v\", str(version), \"-s\", str(scale)]\n",
    "if only_center_face:\n",
    "    cmd.append(\"--only_center_face\")\n",
    "if aligned:\n",
    "    cmd.append(\"--aligned\")\n",
    "if autopilot:\n",
    "    cmd.append(\"--auto\")\n",
    "    cmd.extend([\"--select-by\", select_by])\n",
    "if hardware_aware:\n",
    "    cmd.append(\"--auto-hw\")\n",
    "subprocess.run(cmd, cwd=\"GFPGAN\", check=False)\n",
    "print(\"Done. See GFPGAN/results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- GPU acceleration is optional; uncomment the CUDA wheel index in the install cell to use GPU on Colab.\n",
    "- The inference script will automatically download the GFPGAN v1.4 weights if not present.\n",
    "- For large batches, consider enabling the Real-ESRGAN background upsampler by keeping default settings (it is auto-disabled on CPU)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
